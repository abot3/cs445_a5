{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XVd5QDvoQJvB"
   },
   "source": [
    "Project #5: Video Stitching and Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gd7scc-8QJvE"
   },
   "source": [
    "## CS445: Computational Photography - Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "II0kMh4yULg_"
   },
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtjcEvWArExF"
   },
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python -y\n",
    "# downgrade OpenCV a bit to use SIFT\n",
    "# !pip install opencv-contrib-python==3.4.2.17 --force-reinstall\n",
    "!pip install ffmpeg-python # for converting to video\n",
    "\n",
    "import ffmpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "import gc\n",
    "from numpy.linalg import svd, inv\n",
    "import utils\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGABkLumWBt_"
   },
   "outputs": [],
   "source": [
    "# modify to where you store your project data including utils\n",
    "datadir = \"/home/abot/cs445_comp_photo/cs445_a5\" \n",
    "\n",
    "utilfn = os.path.join(datadir, \"utils.py\")\n",
    "!cp \"$utilfn\" .\n",
    "imagesfn = os.path.join(datadir, \"images\")\n",
    "!cp -r \"$imagesfn\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(182736745)\n",
    "\n",
    "def _reference_homography_filepath():\n",
    "  kRefHomographiesFileName = 'reference_homographies_arr'\n",
    "  kHomographiesFilePath = os.path.join('images', kRefHomographiesFileName)\n",
    "  return kHomographiesFilePath\n",
    "  \n",
    "def _homography_filepath():\n",
    "  kHomographiesFileName = 'homographies_arr'\n",
    "  kHomographiesFilePath = os.path.join('images', kHomographiesFileName)\n",
    "  return kHomographiesFilePath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QagOldZDQJvG"
   },
   "source": [
    "### Part I: Stitch two key frames \n",
    "\n",
    "#### This involves:\n",
    "1. compute homography H between two frames; \n",
    "2. project each frame onto the same surface;\n",
    "3. blend the surfaces.\n",
    "\n",
    "Check that your homography is correct by plotting four points that form a square in frame 270 and their projections in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BulGTlesQJvZ"
   },
   "outputs": [],
   "source": [
    "def score_projection(pt1, pt2):\n",
    "  '''\n",
    "  Score corresponding to the number of inliers for RANSAC\n",
    "  Input: pt1 and pt2 are 2xN arrays of N points such that pt1[:, i] and pt2[:,i] should\n",
    "          be close in Euclidean distance if they are inliers\n",
    "  Outputs: score (scalar count of inliers) and inliers (1xN logical array)\n",
    "  '''\n",
    "  kThreshold = 3.0\n",
    "  _, N = pt1.shape\n",
    "  \n",
    "  euclid_dist = np.sqrt(np.sum(np.power(pt1 - pt2, 2), axis=0))\n",
    "  # (N,) -> (1,N)\n",
    "  euclid_dist = euclid_dist[np.newaxis, :]\n",
    "  assert(euclid_dist.shape == (1,N))\n",
    "  inliers = euclid_dist < kThreshold\n",
    "  assert(inliers.shape == (1,N))\n",
    "  score = np.sum(inliers)\n",
    "  \n",
    "  return score, inliers\n",
    "\n",
    "\n",
    "def auto_homography(Ia,Ib, homography_func=None,normalization_func=None):\n",
    "    '''\n",
    "    Computes a homography that maps points from Ia to Ib\n",
    "\n",
    "    Input: Ia and Ib are images\n",
    "    Output: H is the homography\n",
    "\n",
    "    '''\n",
    "    if Ia.dtype == 'float32' and Ib.dtype == 'float32':\n",
    "        Ia = (Ia*255).astype(np.uint8)\n",
    "        Ib = (Ib*255).astype(np.uint8)\n",
    "    \n",
    "    Ia_gray = cv2.cvtColor(Ia,cv2.COLOR_BGR2GRAY)\n",
    "    Ib_gray = cv2.cvtColor(Ib,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp_a, des_a = sift.detectAndCompute(Ia_gray,None)\n",
    "    kp_b, des_b = sift.detectAndCompute(Ib_gray,None)    \n",
    "    \n",
    "    # BFMatcher with default params\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des_a,des_b, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append(m)\n",
    "   \n",
    "    numMatches = int(len(good))\n",
    "\n",
    "    matches = good\n",
    "\n",
    "    # Xa and Xb are 3xN matrices that contain homogeneous coordinates for the N\n",
    "    # matching points for each image\n",
    "    Xa = np.ones((3,numMatches))\n",
    "    Xb = np.ones((3,numMatches))\n",
    "    \n",
    "    for idx, match_i in enumerate(matches):\n",
    "        Xa[:,idx][0:2] = kp_a[match_i.queryIdx].pt\n",
    "        Xb[:,idx][0:2] = kp_b[match_i.trainIdx].pt\n",
    "\n",
    "    ## RANSAC\n",
    "    niter = 1000\n",
    "    best_score = 0\n",
    "    n_to_sample = 4 # Put the correct number of points here\n",
    "\n",
    "    for t in range(niter):\n",
    "        # estimate homography\n",
    "        subset = np.random.choice(numMatches, n_to_sample, replace=False)\n",
    "        pts1 = Xa[:,subset]\n",
    "        pts2 = Xb[:,subset]\n",
    "        \n",
    "        H_t = homography_func(pts1, pts2, normalization_func) # edit helper code below (computeHomography)\n",
    "\n",
    "        \n",
    "        # score homography\n",
    "        Xb_ = np.dot(H_t, Xa) # project points from first image to second using H\n",
    "        \n",
    "        score_t, inliers_t = score_projection(Xb[:2,:]/Xb[2,:], Xb_[:2,:]/Xb_[2,:])\n",
    "\n",
    "        if score_t > best_score:\n",
    "            best_score = score_t\n",
    "            H = H_t\n",
    "            in_idx = inliers_t\n",
    "    \n",
    "    print('best score: {:02f}'.format(best_score), end='\\r')\n",
    "\n",
    "    # Optionally, you may want to re-estimate H based on inliers\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgPCp98fQJvh"
   },
   "outputs": [],
   "source": [
    "def computeHomography(pts1, pts2, normalization_func=None):\n",
    "    '''\n",
    "    Compute homography that maps from pts1 to pts2 using SVD. Normalization is optional.\n",
    "     \n",
    "    Input: pts1 and pts2 are 3xN matrices for N points in homogeneous\n",
    "    coordinates. \n",
    "    \n",
    "    Output: H is a 3x3 matrix, such that pts2~=H*pts1\n",
    "    '''\n",
    "    kNumCols = 9\n",
    "    three, N = pts1.shape\n",
    "    assert(three == 3)\n",
    "    assert(N == 4)\n",
    "    orig_pts1 = pts1.copy()\n",
    "    orig_pts2 = pts2.copy()\n",
    "    \n",
    "    # Normalize the points (x) matrices\n",
    "    if normalization_func is not None:\n",
    "      pts1, pts2, T, TP = normalization_func(pts1, pts2)\n",
    "      # print(f'pts1\\n {orig_pts1}\\nvs. pts1_p\\n{pts1}')\n",
    "      # print(f'pts2\\n {orig_pts2}\\nvs. pts2_p\\n{pts2}')\n",
    "  \n",
    "    # Aliases for indices that match lecture nomenclature. Homo coords [u, v, w]\n",
    "    u, v = [0, 1]\n",
    "    up, vp = [0, 1]\n",
    "    \n",
    "    A = np.zeros((2*N, kNumCols))\n",
    "    A[::2,0] = -pts1[u, :]  # 0th col\n",
    "    A[::2,1] = -pts1[v, :]  # 1st col\n",
    "    A[::2,2] = -1.0         # 2nd col\n",
    "    # next 3 cols are 0.\n",
    "    A[::2,6] = pts1[u , :] * pts2[up, :]  # 6th col\n",
    "    A[::2,7] = pts1[v , :] * pts2[up, :]  # 7th col\n",
    "    A[::2,8] = pts2[up, :]                # 8th col\n",
    "    \n",
    "    # 1st 3 cols are 0.\n",
    "    A[1::2,3] = -pts1[u, :]  # 3rd col\n",
    "    A[1::2,4] = -pts1[v, :]  # 4th col\n",
    "    A[1::2,5] = -1.0         # 5th col\n",
    "    A[1::2,6] = pts1[u , :] * pts2[vp, :]  # 6th col\n",
    "    A[1::2,7] = pts1[v , :] * pts2[vp, :]  # 7th col\n",
    "    A[1::2,8] = pts2[vp, :]                # 8th col\n",
    "   \n",
    "    # S is sorted in descending order. diag(S)*V = (K,K) * (K,N) so last col is multiplied by smallest singular value.\n",
    "    U, S, Vh = np.linalg.svd(A, compute_uv=True)\n",
    "    h = Vh[-1, :]\n",
    "    H = h.copy().reshape((three, three), order='C')\n",
    "    assert(h[3] == H[1,0])  # Check reshape index correct.\n",
    "    assert(h[5] == H[1,2])\n",
    "    assert(h[7] == H[2,1])\n",
    "    \n",
    "    if normalization_func is not None:\n",
    "      # H_prime back to H.\n",
    "      H = np.linalg.inv(TP) @ H @ T\n",
    "\n",
    "    # For scaling of H matrix by the w', or lamba homo coord see:\n",
    "    # https://math.stackexchange.com/questions/494238/how-to-compute-homography-matrix-h-from-corresponding-points-2d-2d-planar-homog\n",
    "    unscaled_homo = H @ pts1\n",
    "    scaled_homo = unscaled_homo / unscaled_homo[-1, :]\n",
    "    # if not np.allclose(orig_pts2, scaled_homo, rtol=0.01):\n",
    "    #   print('WARNING:')\n",
    "    #   print(f'orig_pts1\\n {orig_pts1}')\n",
    "    #   print(f'orig_pts2\\n {orig_pts2}')\n",
    "    #   print(f'H*pts1_unscaled \\n{unscaled_homo}\\n')\n",
    "    #   print(f'H*pts1_scaled \\n{scaled_homo}\\n')\n",
    "    #   print(f'orig_pts2 - H*pts1 diff {orig_pts2 - scaled_homo}\\n')\n",
    "    #   # assert(np.allclose(orig_pts2, scaled_homo, rtol=0.01))\n",
    "    return H\n",
    "\n",
    "def normalizeHomography(pts1, pts2):\n",
    "  ''' Normalizes the x vectors in the equation x_p = H @ x\n",
    "  \n",
    "  Input: pts1 and pts2 are 3xN matrices for N points in homogeneous\n",
    "  coordinates. \n",
    "  \n",
    "  Output:\n",
    "    pts1_p: transformed (0 mean, unit variance) version of pts1\n",
    "    pts2_p: transformed (0 mean, unit variance) version of pts2\n",
    "    T: the transform corresponding to pts1\n",
    "    TP: the transform corresponding to pts2:\n",
    "  \n",
    "  We compute the homography on the transformed H so all points are the same scale\n",
    "  around ~1. To invert the transform and recover original, unnormalized H, we can\n",
    "  do the following:\n",
    "      H = inv(TP) @ HP @T, \n",
    " \n",
    "  pts2~=H*pts1, so pts2 is x_p, and pts1 is x.\n",
    "  \n",
    "  ~x = T @ x\n",
    "  ~x_p = Tp @ x_p\n",
    "  \n",
    "  Where ~x, and ~x_p are transformed versions of x and x_p with ~0 mean and unit\n",
    "  variance.\n",
    "  '''\n",
    "  T = np.diag([1.0,1.0,1.0])\n",
    "  TP = np.diag([1.0,1.0,1.0])\n",
    "  sigma_T =  [1.0 / (e if e != 0.0 else 1e-9) for e in [np.std(pts1[0,:]), np.std(pts1[1,:]), 1.0]]  # x,y,1\n",
    "  sigma_TP = [1.0 / (e if e != 0.0 else 1e-9) for e in [np.std(pts2[0,:]), np.std(pts2[1,:]), 1.0]]  # x,y,1\n",
    "  sigma_T = np.diag(sigma_T)\n",
    "  sigma_TP = np.diag(sigma_TP)\n",
    "  \n",
    "  mu_x, mu_y   = (np.mean(pts1[0,:]), np.mean(pts1[1,:]))  # x,y\n",
    "  mu_xp, mu_yp = (np.mean(pts2[0,:]), np.mean(pts2[1,:]))  # x,y\n",
    "  \n",
    "  T[0, -1] = -mu_x\n",
    "  T[1, -1] = -mu_y\n",
    "  TP[0, -1] = -mu_xp\n",
    "  TP[1, -1] = -mu_yp\n",
    "  # print(f'T\\n {T}')\n",
    "  # print(f'TP\\n {TP}')\n",
    "  \n",
    "  T = sigma_T @ T\n",
    "  TP = sigma_TP @ TP\n",
    "  # print(f'T  {T.shape}\\n {T}')\n",
    "  # print(f'TP {TP.shape}\\n {TP}')\n",
    "  \n",
    "  pts1_p = T @ pts1\n",
    "  pts2_p = TP @ pts2\n",
    "  \n",
    "  return pts1_p, pts2_p, T, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fkiAbFqvQJvo"
   },
   "outputs": [],
   "source": [
    "# images location\n",
    "im1 = './images/input/frames/f0270.jpg'\n",
    "im2 = './images/input/frames/f0450.jpg'\n",
    "\n",
    "# Load an color image in grayscale\n",
    "im1 = cv2.imread(im1)\n",
    "im2 = cv2.imread(im2)\n",
    "\n",
    "H = auto_homography(im1,im2, computeHomography, normalizeHomography)\n",
    "# H = auto_homography(im1,im2, computeHomography)\n",
    "print(H/H.max()) \n",
    "\n",
    "# plot the frames here\n",
    "box_pts = np.array([[300, 400, 400, 300, 300], [100, 100, 200, 200, 100], [1, 1, 1, 1, 1]])\n",
    "plt.figure()\n",
    "plt.imshow(im1[:,:,[2,1,0]])\n",
    "plt.plot(box_pts[0,:], box_pts[1, :], 'r-')\n",
    "\n",
    "# TO DO: project points into im2 and display the projected lines on im2\n",
    "unscaled_homo = H @ box_pts\n",
    "scaled_homo = unscaled_homo / unscaled_homo[-1, :]\n",
    "plt.figure()\n",
    "plt.imshow(im2[:,:,[2,1,0]])\n",
    "plt.plot(scaled_homo[0,:], scaled_homo[1, :], 'r-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDd6PwrGQJvw"
   },
   "outputs": [],
   "source": [
    "projectedWidth = 1600\n",
    "projectedHeight = 600\n",
    "Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "canvas = np.zeros((projectedHeight, projectedWidth))\n",
    "\n",
    "# Projects im1 and im2 according to T1 and T2 to an image of size WxH and then\n",
    "# blends the projected images by filling any zero values in projIm2 with values\n",
    "# from projIm1\n",
    "projIm1 = cv2.warpPerspective(im1, np.dot(Tr,H), (projectedWidth, projectedHeight))\n",
    "projIm2 = cv2.warpPerspective(im2, Tr, (projectedWidth, projectedHeight))\n",
    "blendOut = utils.blendImages(projIm1, projIm2) \n",
    "\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.imshow(blendOut[:,:,[2,1,0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1PigMkPQJv4"
   },
   "source": [
    "### Part II: Panorama using five key frames\n",
    "\n",
    "Produce a panorama by mapping five key frames [90, 270, 450, 630, 810] onto the same reference frame 450.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SgCFur1QJwC"
   },
   "outputs": [],
   "source": [
    "key_frames_idx = np.array([90, 270, 450, 630, 810])-1\n",
    "\n",
    "frames = np.zeros((len(key_frames_idx), im1.shape[0], im1.shape[1], im1.shape[2]),dtype='uint8')\n",
    "for n in range(len(key_frames_idx)):\n",
    "  frames[n] = cv2.imread(\"./images/input/frames/f0{num}.jpg\".format(num=str(key_frames_idx[n]+1).zfill(3)))\n",
    "\n",
    "N = len(frames)\n",
    "kKeyFrameHomographies = np.zeros((N, 3, 3), dtype=np.float32)\n",
    "\n",
    "def warp_frames(frames: List[np.ndarray]) -> np.ndarray:\n",
    "  _, oH, oW, _ = frames.shape\n",
    "  projectedWidth = 1600\n",
    "  projectedHeight = 600\n",
    "  Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "  canvas = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "  \n",
    "  # We reference everything to the 450th frame. Add 1 so we keep the black\n",
    "  # pixels when using blendImages.\n",
    "  kRefFrame = frames[N//2].copy()\n",
    "  prev_H = np.diag([1.0, 1.0, 1.0])\n",
    "  prev_frame = kRefFrame.copy()\n",
    "  count = 0\n",
    "  for i, f in enumerate(frames[N//2-1::-1]):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.imshow(prev_frame[:,:,[2,1,0]])\n",
    "    plt.title(f'PrevFrame {count}')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.imshow(f[:,:,[2,1,0]])\n",
    "    plt.title(f'Frame {count}')\n",
    "    plt.show()\n",
    "    c = prev_frame.copy()\n",
    "    c[prev_frame == 0] = 1\n",
    "    H = prev_H @ auto_homography(f, prev_frame, computeHomography, normalizeHomography)\n",
    "    p1 = cv2.warpPerspective(f.copy(), np.dot(Tr, H), (projectedWidth, projectedHeight))\n",
    "    p_ref = cv2.warpPerspective(c, np.dot(Tr, prev_H), (projectedWidth, projectedHeight))\n",
    "    blendOut = utils.blendImages(p1.copy(), p_ref.copy())  # Ref is second argument.\n",
    "    plt.figure(figsize=(25,20))\n",
    "    plt.imshow(blendOut[:,:,[2,1,0]])\n",
    "    plt.title(f'BlendOut {count}')\n",
    "    plt.show()\n",
    "    canvas = utils.blendImages(blendOut, canvas)\n",
    "    \n",
    "    inv_p1 = cv2.warpPerspective(p1.copy(), np.linalg.inv(np.dot(Tr, H)), (oW, oH))#, flags=cv2.WARP_INVERSE_MAP)\n",
    "    inv_p_ref = cv2.warpPerspective(p_ref.copy(), np.linalg.inv(np.dot(Tr, prev_H)),\n",
    "                                    (oW, oH))#, flags=cv2.WARP_INVERSE_MAP)\n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.subplot(121),plt.imshow(p1[:,:,[2,1,0]]),plt.title('Frame {count}')\n",
    "    plt.subplot(122),plt.imshow(inv_p1[:,:,[2,1,0]]),plt.title(f'Inverse Frame {count}')\n",
    "    plt.show()\n",
    "    plt.subplot(121),plt.imshow(p_ref[:,:,[2,1,0]]),plt.title('Ref Frame {count}')\n",
    "    plt.subplot(122),plt.imshow(inv_p_ref[:,:,[2,1,0]]),plt.title(f'Inverse Ref Frame {count}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Update loop variables.\n",
    "    kKeyFrameHomographies[N//2-1-i, :, :] = H \n",
    "    prev_H = H.copy()\n",
    "    prev_frame = f.copy()\n",
    "    count += 1\n",
    "    \n",
    "  prev_H = np.diag([1.0, 1.0, 1.0])\n",
    "  prev_frame = kRefFrame.copy()\n",
    "  count = 0\n",
    "  for i,f in enumerate(frames[N//2 + 1::1]):\n",
    "    H = prev_H @ auto_homography(f, prev_frame, computeHomography, normalizeHomography)\n",
    "    c = prev_frame.copy()\n",
    "    c[prev_frame == 0] = 1\n",
    "    p1 = cv2.warpPerspective(f, np.dot(Tr, H), (projectedWidth, projectedHeight))\n",
    "    p_ref = cv2.warpPerspective(c, np.dot(Tr, prev_H), (projectedWidth, projectedHeight))\n",
    "    blendOut = utils.blendImages(p1, p_ref)  # Ref is second argument.\n",
    "    canvas = utils.blendImages(blendOut, canvas)\n",
    "    # Update loop variables.\n",
    "    kKeyFrameHomographies[N//2+1+i, :, :] = H\n",
    "    prev_H = H.copy()\n",
    "    prev_frame = f.copy()\n",
    "    \n",
    "  kKeyFrameHomographies[N//2, :, :] = np.diag([1.0, 1.0, 1.0])\n",
    "  return canvas\n",
    "\n",
    "canvas = warp_frames(frames)\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.imshow(canvas[:,:,[2,1,0]])\n",
    "cv2.imwrite('part2_panorama.jpg', canvas)\n",
    "\n",
    "print(f'Key Frame Homographies \\n{kKeyFrameHomographies}')\n",
    "np.save(os.path.join('images', 'kKeyFrameHomographies_arr'), kKeyFrameHomographies, allow_pickle=True)\n",
    "np.save(_reference_homography_filepath(), kKeyFrameHomographies, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Cleanup'''\n",
    "del im1\n",
    "del im2\n",
    "del frames\n",
    "del kKeyFrameHomographies\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APdyMw_NQJwK"
   },
   "source": [
    "### Part 3: Map the video to the reference plane\n",
    "\n",
    "Project each frame onto the reference frame (using same size panorama) to create a video that shows the portion of the panorama revealed by each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_LONG_STUFF = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAXyIkYyQJwT"
   },
   "outputs": [],
   "source": [
    "# read all the images\n",
    "dir_frames = 'images/input/frames'\n",
    "filenames = []\n",
    "filesinfo = os.scandir(dir_frames)\n",
    "\n",
    "filenames = [f.path for f in filesinfo if f.name.endswith(\".jpg\")]\n",
    "filenames.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "frameCount = len(filenames)\n",
    "frameHeight, frameWidth, frameChannels = cv2.imread(filenames[0]).shape\n",
    "frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype='uint8')\n",
    "\n",
    "for idx, file_i in enumerate(filenames):\n",
    "  frames[idx] = cv2.imread(file_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0b8N2rP9PDVL"
   },
   "outputs": [],
   "source": [
    "# TO DO part 3 solution\n",
    "# create your video (see tips)\n",
    "\n",
    "  \n",
    "def save_homographies(homographies: np.ndarray):\n",
    "  '''\n",
    "  Input:\n",
    "    homographies: (N,3,3)\n",
    "  '''\n",
    "  print(f'Saving homographies.')\n",
    "  np.save(_homography_filepath(), homographies, allow_pickle=True)\n",
    "  \n",
    "def get_homographies() -> np.ndarray:\n",
    "  homographies = np.load(_homography_filepath() + '.npy', allow_pickle=True)\n",
    "  print(f'Homographies shape {homographies.shape}')\n",
    "  return homographies\n",
    "\n",
    "def _video_filepath():\n",
    "  kVideoFileName = 'video_frames_arr'\n",
    "  kVideoFilePath = os.path.join('images', kVideoFileName)\n",
    "  return kVideoFilePath\n",
    "\n",
    "def save_video(video_frames: np.ndarray):\n",
    "  '''\n",
    "  Input:\n",
    "    video_frames: (900,3,3)\n",
    "  '''\n",
    "  print(f'Saving video.')\n",
    "  np.save(_video_filepath(), video_frames, allow_pickle=True)\n",
    "  \n",
    "def get_video_frames() -> np.ndarray:\n",
    "  video_frames = np.load(_video_filepath() + '.npy', allow_pickle=True)\n",
    "  print(f'video_frames.shape {video_frames.shape}')\n",
    "  return video_frames\n",
    "\n",
    "def get_closest_key_frame(frame_index):\n",
    "  kKeyFrameIndices = np.array([90, 270, 450, 630, 810])-1\n",
    "  assert(frame_index >= 0 and frame_index < 900)\n",
    "  closest_index = np.argmin(np.abs(kKeyFrameIndices - frame_index))\n",
    "  return kKeyFrameIndices[closest_index], closest_index\n",
    "\n",
    "if RUN_LONG_STUFF:\n",
    "  # Set up the Ref frames. We find homography to closest one of these.\n",
    "  N, H, W, C = frames.shape\n",
    "\n",
    "  # Set up the canvas.\n",
    "  projectedWidth = 1600\n",
    "  projectedHeight = 600\n",
    "  Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "  canvas = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "\n",
    "  # Arrays to store transformed frames.\n",
    "  reference_homographies = np.load(_reference_homography_filepath() + '.npy', allow_pickle=True)\n",
    "  homographies = np.zeros((N, 3, 3))\n",
    "  video_frames = np.zeros((N,) + canvas.shape, dtype='uint8')\n",
    "  # (len(np.arange(0,N,100)),)\n",
    "  print(f'Video Frames shape {video_frames.shape}, type: {video_frames.dtype}')\n",
    "\n",
    "  count = 0\n",
    "  debug_3 = False\n",
    "  # for i in np.arange(0,N,100):\n",
    "  for i in np.arange(0,N,1):\n",
    "    print(f'Building video ... processing frame:{i:4}, count:{count:4}', end='\\r')\n",
    "    f = frames[i]\n",
    "    ref_idx, ref_arr_idx = get_closest_key_frame(i)\n",
    "    ref = frames[ref_idx].copy()\n",
    "    ref_H = reference_homographies[ref_arr_idx, ...]\n",
    "    H = ref_H @ auto_homography(f, ref, computeHomography, normalizeHomography)\n",
    "    ref[ref == 0] = 1\n",
    "\n",
    "    if debug_3:\n",
    "      plt.figure(figsize=(10,8))\n",
    "      plt.imshow(ref[:,:,[2,1,0]])\n",
    "      plt.title(f'Ref frame {count}')\n",
    "      plt.show()\n",
    "      plt.figure(figsize=(10,8))\n",
    "      plt.imshow(f[:,:,[2,1,0]])\n",
    "      plt.title(f'Frame {count}')\n",
    "      plt.show()\n",
    "\n",
    "    p1 = cv2.warpPerspective(f, np.dot(Tr, H), (projectedWidth, projectedHeight))\n",
    "    p_ref = cv2.warpPerspective(ref, np.dot(Tr, ref_H), (projectedWidth, projectedHeight))\n",
    "    blendOut = utils.blendImages(p1, p_ref)  # Ref is second argument.\n",
    "    canvas = utils.blendImages(blendOut, canvas)\n",
    "\n",
    "    if debug_3:\n",
    "      plt.figure(figsize=(25,20))\n",
    "      plt.imshow(blendOut[:,:,[2,1,0]])\n",
    "      plt.title(f'BlendOut {count}')\n",
    "      plt.show()\n",
    "      plt.figure(figsize=(25,20))\n",
    "      plt.imshow(canvas[:,:,[2,1,0]])\n",
    "      plt.title(f'Canvas')\n",
    "      plt.show()\n",
    "\n",
    "    homographies[i, :, :] = H\n",
    "    video_frames[i, ...] = p1\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the video to disk\n",
    "if RUN_LONG_STUFF:\n",
    "  save_homographies(homographies)\n",
    "  save_video(video_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF:\n",
    "  # Convert BGR to RGB, ffmpeg wants RGB.\n",
    "  video_frames = get_video_frames()\n",
    "  utils.vidwrite_from_numpy('part3_video_out.mp4',video_frames[...,[2,1,0]], framerate=30, vcodec='libx264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the video from disk\n",
    "# video_ref_homography = np.load(_reference_homography_filepath() + '.npy',allow_pickle=True)\n",
    "# video_homography = get_homographies()\n",
    "# video = get_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Cleanup memory'''\n",
    "del frames\n",
    "del video_frames\n",
    "del homographies\n",
    "del reference_homographies\n",
    "del canvas\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dg2O-zH_QJw0"
   },
   "source": [
    "### Part 4: Create background panorama\n",
    "\n",
    "Create a background panorama based on the result from Part 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_LONG_STUFF_PT4 = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ammv-rsQJw1"
   },
   "outputs": [],
   "source": [
    "# Load the video from disk\n",
    "if RUN_LONG_STUFF_PT4:\n",
    "  video_ref_homographies = np.load(_reference_homography_filepath() + '.npy',allow_pickle=True)\n",
    "  video_homographies = get_homographies()\n",
    "  frames = get_video_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF_PT4:\n",
    "  video_frame_medians = np.zeros(frames.shape[1:], dtype=np.uint8)\n",
    "  # frames_masked = ma.masked_array(frames, frames > 1).astype(np.uint8)\n",
    "  # video_frame_medians[:,:,:] = ma.median(frames_masked, axis=0).astype(np.uint8)\n",
    "  for r in range(frames.shape[1]):\n",
    "    # for c in range(frames.shape[2]):\n",
    "    frames_masked = ma.masked_array(frames[:, r, :, :], frames[:, r, :, :] <= 1).astype(np.uint8)\n",
    "    video_frame_medians[r, :, :] = ma.median(frames_masked, axis=0).astype(np.uint8)\n",
    "    print(f'row {r}.', end='\\r')\n",
    "  # assert(video_frame_medians.shape == frames.shape[1:])\n",
    "  print(f'medians.shape {video_frame_medians.shape}')\n",
    "  video_frame_medians = video_frame_medians[np.newaxis, ...]\n",
    "  video_frame_medians = np.repeat(video_frame_medians, repeats=(900,), axis=0)\n",
    "  print(f'video_frame_medians shape: {video_frame_medians.shape}')\n",
    "\n",
    "  video_frame_medians_diff = np.abs(frames - video_frame_medians, dtype=np.uint8)\n",
    "  # If the pixel is abs(kThreshold) from the median we replace it with the median.\n",
    "  kThreshold = 5\n",
    "  print(f'is_bg_mask {np.sum(video_frame_medians_diff < kThreshold)} of {video_frame_medians_diff.size} total are 1=unmasked.')\n",
    "\n",
    "  modified_frames = frames.copy()\n",
    "  print(f'modified shape {video_frame_medians.shape}')\n",
    "  # Set modified = values where mask == 1, else modified unchanged.\n",
    "  np.putmask(modified_frames, mask=(video_frame_medians_diff > kThreshold), values=video_frame_medians)\n",
    "\n",
    "  gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF_PT4:\n",
    "  # Set up the Ref frames. We find homography to closest one of these.\n",
    "  N, H, W, C = modified_frames.shape\n",
    "  # Set up the canvas.\n",
    "  projectedWidth = 1600\n",
    "  projectedHeight = 600\n",
    "  Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "  canvas = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "  canvas2 = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "  for i in np.arange(0,N,10):\n",
    "      debug_3 = True\n",
    "      print(f'Rendering modified frames ... processing frame:{i:4}, count:{i:4}')\n",
    "      f = modified_frames[i]\n",
    "      f2 = frames[i]\n",
    "      # ref_idx, ref_arr_idx = get_closest_key_frame(i)\n",
    "      # ref = frames[ref_idx].copy()\n",
    "      # ref_H = video_ref_homographies[ref_arr_idx, ...]\n",
    "      # H = ref_H @ video_homographies[i, ...]\n",
    "      # ref[ref == 0] = 1\n",
    "\n",
    "      # if debug_3:\n",
    "      #   plt.figure(figsize=(10,8))\n",
    "      #   plt.imshow(ref[:,:,[2,1,0]])\n",
    "      #   plt.title(f'Ref frame {i}')\n",
    "      #   plt.show()\n",
    "      #   plt.figure(figsize=(10,8))\n",
    "      #   plt.imshow(f[:,:,[2,1,0]])\n",
    "      #   plt.title(f'Frame {i}')\n",
    "      #   plt.show()\n",
    "\n",
    "      # p1 = cv2.warpPerspective(f, np.dot(Tr, H), (projectedWidth, projectedHeight))\n",
    "      # p_ref = cv2.warpPerspective(ref, np.dot(Tr, ref_H), (projectedWidth, projectedHeight))\n",
    "      # blendOut = utils.blendImages(p1, p_ref)  # Ref is second argument.\n",
    "      canvas = utils.blendImages(f, canvas)\n",
    "      canvas2 = utils.blendImages(f2, canvas2)\n",
    "\n",
    "      if debug_3:\n",
    "        # plt.figure(figsize=(25,20))\n",
    "        # plt.imshow(blendOut[:,:,[2,1,0]])\n",
    "        # plt.title(f'BlendOut {i}')\n",
    "        # plt.show()\n",
    "        plt.figure(figsize=(25,20))\n",
    "        plt.imshow(canvas[:,:,[2,1,0]])\n",
    "        plt.title(f'Canvas')\n",
    "        plt.show()\n",
    "\n",
    "  cv2.imwrite('part4_background_panorama.jpg', canvas)\n",
    "  cv2.imwrite('part4_all_panorama.jpg', canvas2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IqzWZwrQJw4"
   },
   "source": [
    "### Part 5: Create background movie\n",
    "\n",
    "Generate a movie that looks like the input movie but shows only background pixels. For each frame of the movie, you need to estimate a projection from the panorama to that frame. Your solution can use the background image you created in Part 4 and the per-frame homographies you created in Part 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_LONG_STUFF_PT5 = True\n",
    "del frames\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dzy12p1bQJw4"
   },
   "outputs": [],
   "source": [
    "# Load the video from disk\n",
    "if RUN_LONG_STUFF_PT5:\n",
    "  video_ref_homographies = np.load(_reference_homography_filepath() + '.npy',allow_pickle=True)\n",
    "  video_homographies = get_homographies()\n",
    "  # frames = get_video_frames()\n",
    "  panorama_bg = cv2.imread('part4_background_panorama.jpg')\n",
    "  panorama_all = cv2.imread('part4_all_panorama.jpg')\n",
    "  \n",
    "  dir_frames = 'images/input/frames'\n",
    "  filenames = []\n",
    "  filesinfo = os.scandir(dir_frames)\n",
    "\n",
    "  filenames = [f.path for f in filesinfo if f.name.endswith(\".jpg\")]\n",
    "  filenames.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "  frameCount = len(filenames)\n",
    "  frameHeight, frameWidth, frameChannels = cv2.imread(filenames[0]).shape\n",
    "  frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype='uint8')\n",
    "  \n",
    "  assert(frameCount == video_homographies.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if RUN_LONG_STUFF_PT5:\n",
    "#   video_frame_means = np.zeros(frames.shape[1:], dtype=np.uint8)\n",
    "#   # frames_masked = ma.masked_array(frames, frames > 1).astype(np.uint8)\n",
    "#   # video_frame_means[:,:,:] = ma.median(frames_masked, axis=0).astype(np.uint8)\n",
    "#   for r in range(frames.shape[1]):\n",
    "#     # for c in range(frames.shape[2]):\n",
    "#     frames_masked = ma.masked_array(frames[:, r, :, :], frames[:, r, :, :] <= 1).astype(np.uint8)\n",
    "#     video_frame_means[r, :, :] = ma.median(frames_masked, axis=0).astype(np.uint8)\n",
    "#     print(f'row {r}.')\n",
    "#   # assert(video_frame_means.shape == frames.shape[1:])\n",
    "#   print(f'means.shape {video_frame_means.shape}')\n",
    "#   video_frame_means = video_frame_means[np.newaxis, ...]\n",
    "#   video_frame_means = np.repeat(video_frame_means, repeats=(900,), axis=0)\n",
    "#   print(f'video_frame_means shape: {video_frame_means.shape}')\n",
    "\n",
    "#   video_frame_means_diff = np.abs(frames - video_frame_means, dtype=np.uint8)\n",
    "#   kThreshold = 5\n",
    "#   print(f'is_bg_mask {np.sum(video_frame_means_diff < kThreshold)} of {video_frame_means_diff.size} total are 1=unmasked.')\n",
    "\n",
    "#   modified_frames = frames.copy()\n",
    "#   print(f'modified shape {video_frame_means.shape}')\n",
    "#   # Set modified = values where mask == 1, else modified unchanged.\n",
    "#   np.putmask(modified_frames, mask=(video_frame_means_diff > kThreshold), values=video_frame_means)\n",
    "\n",
    "#   gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('sudokusmall.jpg')\n",
    "rows,cols,ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "dst = cv2.warpPerspective(img,M,(300,300))\n",
    " \n",
    "plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "plt.show()\n",
    "\n",
    "_, inv_M = cv2.invert(M)\n",
    "# inverted = cv2.warpPerspective(dst, M, img.shape[:2], flags=cv2.WARP_INVERSE_MAP)\n",
    "inverted = cv2.warpPerspective(dst, inv_M, img.shape[:2])\n",
    "plt.subplot(121),plt.imshow(dst),plt.title('Output')\n",
    "plt.subplot(122),plt.imshow(inverted),plt.title('Inverted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_key_frame(frame_index):\n",
    "  kKeyFrameIndices = np.array([90, 270, 450, 630, 810])-1\n",
    "  assert(frame_index >= 0 and frame_index < 900)\n",
    "  closest_index = np.argmin(np.abs(kKeyFrameIndices - frame_index))\n",
    "  return kKeyFrameIndices[closest_index], closest_index\n",
    "\n",
    "if RUN_LONG_STUFF_PT5:\n",
    "  # Set up the Ref frames. We find homography to closest one of these.\n",
    "  N, Height, Width, C = frames.shape\n",
    "  # Set up the canvas.\n",
    "  projectedWidth, projectedHeight, _ = panorama_bg.shape\n",
    "  Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "  \n",
    "  print(f'Tr \\n{Tr}')\n",
    "  print(f'Tr Inv \\n{np.linalg.inv(Tr)}')\n",
    "  # canvas = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "  for i in np.arange(0,N,1):\n",
    "      debug_5 = True\n",
    "      print(f'Rendering modified frames ... processing frame:{i:4}, count:{i:4}')\n",
    "      # ref_idx, ref_arr_idx = get_closest_key_frame(i)\n",
    "      # ref_H = video_ref_homographies[ref_arr_idx, ...]\n",
    "      # H = ref_H @ video_homographies[i, ...]\n",
    "      H = video_homographies[i, ...]\n",
    "\n",
    "      # if debug_3:\n",
    "      #   plt.figure(figsize=(10,8))\n",
    "      #   plt.imshow(ref[:,:,[2,1,0]])\n",
    "      #   plt.title(f'Ref frame {i}')\n",
    "      #   plt.show()\n",
    "      #   plt.figure(figsize=(10,8))\n",
    "      #   plt.imshow(f[:,:,[2,1,0]])\n",
    "      #   plt.title(f'Frame {i}')\n",
    "      #   plt.show()\n",
    "\n",
    "      # p1 = cv2.warpPerspective(f, np.dot(Tr, H), (projectedWidth, projectedHeight))\n",
    "      # p_ref = cv2.warpPerspective(ref, np.dot(Tr, ref_H), (projectedWidth, projectedHeight))\n",
    "      # blendOut = utils.blendImages(p1, p_ref)  # Ref is second argument.\n",
    "      # canvas = utils.blendImages(f, canvas)\n",
    "      fwd_H = np.dot(Tr, H)\n",
    "      inv_H = np.dot(np.linalg.inv(H), np.linalg.inv(Tr))\n",
    "      # print(f'H \\n{H}')\n",
    "      # print(f'H inv\\n{np.linalg.inv(H)}')\n",
    "      # print(f'fwd_H \\n{fwd_H}')\n",
    "      # print(f'inv_H \\n{inv_H}')\n",
    "      # print(f'fwd inv dot ~= 1\\n{np.dot(inv_H, fwd_H)}')\n",
    "      ret, cv2_inv_H = cv2.invert(np.dot(Tr, H))\n",
    "      assert(np.allclose(inv_H, cv2_inv_H))\n",
    "      # inverted = cv2.warpPerspective(panorama, cv2_inv_H,\n",
    "      #                                (frameWidth, frameHeight))\n",
    "      inverted = cv2.warpPerspective(panorama_bg, fwd_H,\n",
    "                                     (frameWidth, frameHeight), flags=cv2.WARP_INVERSE_MAP)\n",
    "      frames[i, ...] = inverted\n",
    "\n",
    "      if debug_5 and (i % 50) == 0:\n",
    "        # plt.figure(figsize=(25,20))\n",
    "        # plt.imshow(blendOut[:,:,[2,1,0]])\n",
    "        # plt.title(f'BlendOut {i}')\n",
    "        # plt.show()\n",
    "        plt.figure(figsize=(25,20))\n",
    "        plt.imshow(frames[i][:,:,[2,1,0]])\n",
    "        plt.title(f'Frame Inverted {i}')\n",
    "        plt.show()\n",
    "\n",
    "  np.save('part5_frames_arr.npy', frames, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF_PT5:\n",
    "  video_frames = np.load('part5_frames_arr.npy', allow_pickle=True)\n",
    "  # Convert BGR to RGB, ffmpeg wants RGB.\n",
    "  utils.vidwrite_from_numpy('part5_video_out.mp4', video_frames[...,[2,1,0]], framerate=30, vcodec='libx264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF_PT5:\n",
    "  del frames\n",
    "  del video_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0y7i7hBQJw7"
   },
   "source": [
    "### Part 6: Create foreground movie\n",
    "\n",
    "In the background video, moving objects are removed. In each frame, those pixels that are different enough than the background color are considered foreground. For each frame determine foreground pixels and generate a movie that emphasizes or includes only foreground pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_LONG_STUFF_PT6 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF_PT6:\n",
    "  video_ref_homographies = np.load(_reference_homography_filepath() + '.npy',allow_pickle=True)\n",
    "  video_homographies = get_homographies()\n",
    "  frames = get_video_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RUN_LONG_STUFF_PT6:\n",
    "#   video_frame_means = np.zeros(frames.shape[1:], dtype=np.uint8)\n",
    "#   # frames_masked = ma.masked_array(frames, frames > 1).astype(np.uint8)\n",
    "#   # video_frame_means[:,:,:] = ma.median(frames_masked, axis=0).astype(np.uint8)\n",
    "#   for r in range(frames.shape[1]):\n",
    "#     # for c in range(frames.shape[2]):\n",
    "#     frames_masked = ma.masked_array(frames[:, r, :, :], frames[:, r, :, :] <= 1).astype(np.uint8)\n",
    "#     video_frame_means[r, :, :] = ma.median(frames_masked, axis=0).astype(np.uint8)\n",
    "#     print(f'row {r}.', end='\\r')\n",
    "#   # assert(video_frame_means.shape == frames.shape[1:])\n",
    "#   print(f'means.shape {video_frame_means.shape}')\n",
    "#   video_frame_means = video_frame_means[np.newaxis, ...]\n",
    "#   video_frame_means = np.repeat(video_frame_means, repeats=(900,), axis=0)\n",
    "#   print(f'video_frame_means shape: {video_frame_means.shape}')\n",
    "\n",
    "#   video_frame_means_diff = np.abs(frames - video_frame_means, dtype=np.uint8)\n",
    "#   # If the pixel is abs(kThreshold) from the median we replace it with the median.\n",
    "#   kThreshold = 20\n",
    "#   print(f'is_bg_mask {np.sum(video_frame_means_diff > kThreshold)} of {video_frame_means_diff.size} total are 1=unmasked.')\n",
    "\n",
    "#   modified_frames = frames.copy()\n",
    "#   print(f'modified shape {video_frame_means.shape}')\n",
    "#   # Set modified = values where mask == 1, else modified unchanged.\n",
    "#   np.putmask(modified_frames, mask=(video_frame_means_diff < kThreshold), values=video_frame_means)\n",
    "\n",
    "#   gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RUN_LONG_STUFF_PT6:\n",
    "#   # Set up the Ref frames. We find homography to closest one of these.\n",
    "#   N, H, W, C = modified_frames.shape\n",
    "#   # Set up the canvas.\n",
    "#   projectedWidth = 1600\n",
    "#   projectedHeight = 600\n",
    "#   Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "#   canvas = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "#   canvas2 = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "#   for i in np.arange(0,N,100):\n",
    "#       debug_3 = True\n",
    "#       print(f'Rendering modified frames ... processing frame:{i:4}, count:{i:4}')\n",
    "#       f = modified_frames[i]\n",
    "#       f2 = frames[i]\n",
    "#       # ref_idx, ref_arr_idx = get_closest_key_frame(i)\n",
    "#       # ref = frames[ref_idx].copy()\n",
    "#       # ref_H = video_ref_homographies[ref_arr_idx, ...]\n",
    "#       # H = ref_H @ video_homographies[i, ...]\n",
    "#       # ref[ref == 0] = 1\n",
    "\n",
    "#       # if debug_3:\n",
    "#       #   plt.figure(figsize=(10,8))\n",
    "#       #   plt.imshow(ref[:,:,[2,1,0]])\n",
    "#       #   plt.title(f'Ref frame {i}')\n",
    "#       #   plt.show()\n",
    "#       #   plt.figure(figsize=(10,8))\n",
    "#       #   plt.imshow(f[:,:,[2,1,0]])\n",
    "#       #   plt.title(f'Frame {i}')\n",
    "#       #   plt.show()\n",
    "\n",
    "#       # p1 = cv2.warpPerspective(f, np.dot(Tr, H), (projectedWidth, projectedHeight))\n",
    "#       # p_ref = cv2.warpPerspective(ref, np.dot(Tr, ref_H), (projectedWidth, projectedHeight))\n",
    "#       # blendOut = utils.blendImages(p1, p_ref)  # Ref is second argument.\n",
    "#       canvas = utils.blendImages(f, canvas)\n",
    "#       canvas2 = utils.blendImages(f2, canvas2)\n",
    "\n",
    "#       if debug_3:\n",
    "#         # plt.figure(figsize=(25,20))\n",
    "#         # plt.imshow(blendOut[:,:,[2,1,0]])\n",
    "#         # plt.title(f'BlendOut {i}')\n",
    "#         # plt.show()\n",
    "#         plt.figure(figsize=(25,20))\n",
    "#         plt.imshow(canvas[:,:,[2,1,0]])\n",
    "#         plt.title(f'Canvas')\n",
    "#         plt.show()\n",
    "\n",
    "#   cv2.imwrite('part6_foreground_panorama.jpg', canvas)\n",
    "#   cv2.imwrite('part6_all_panorama.jpg', canvas2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF_PT6: \n",
    "  video_ref_homographies = np.load(_reference_homography_filepath() + '.npy',allow_pickle=True)\n",
    "  video_homographies = get_homographies()\n",
    "  panorama_bg = cv2.imread('part4_background_panorama.jpg')\n",
    "  panorama_all = cv2.imread('part4_all_panorama.jpg')\n",
    "  \n",
    "  dir_frames = 'images/input/frames'\n",
    "  filenames = []\n",
    "  filesinfo = os.scandir(dir_frames)\n",
    "\n",
    "  filenames = [f.path for f in filesinfo if f.name.endswith(\".jpg\")]\n",
    "  filenames.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "  frameCount = len(filenames)\n",
    "  frameHeight, frameWidth, frameChannels = cv2.imread(filenames[0]).shape\n",
    "  frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype='uint8')\n",
    "  \n",
    "  orig_frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype='uint8')\n",
    "  for n in range(len(key_frames_idx)):\n",
    "    orig_frames[n] = cv2.imread(\"./images/input/frames/f0{num}.jpg\".format(num=str(key_frames_idx[n]+1).zfill(3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mcg6jC_9QJw8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF_PT6: \n",
    "  video_ref_homographies = np.load(_reference_homography_filepath() + '.npy',allow_pickle=True)\n",
    "  video_homographies = get_homographies()\n",
    "  panorama_bg = cv2.imread('part4_background_panorama.jpg')\n",
    "  panorama_all = cv2.imread('part4_all_panorama.jpg')\n",
    "  \n",
    "  dir_frames = 'images/input/frames'\n",
    "  filenames = []\n",
    "  filesinfo = os.scandir(dir_frames)\n",
    "\n",
    "  filenames = [f.path for f in filesinfo if f.name.endswith(\".jpg\")]\n",
    "  filenames.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "  frameCount = len(filenames)\n",
    "  frameHeight, frameWidth, frameChannels = cv2.imread(filenames[0]).shape\n",
    "  frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype='uint8')\n",
    "  \n",
    "  orig_frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype='uint8')\n",
    "  for idx, file_i in enumerate(filenames):\n",
    "    orig_frames[idx] = cv2.imread(file_i)\n",
    "\n",
    "  \n",
    "# TO DO part 6\n",
    "def get_closest_key_frame(frame_index):\n",
    "  kKeyFrameIndices = np.array([90, 270, 450, 630, 810])-1\n",
    "  assert(frame_index >= 0 and frame_index < 900)\n",
    "  closest_index = np.argmin(np.abs(kKeyFrameIndices - frame_index))\n",
    "  return kKeyFrameIndices[closest_index], closest_index\n",
    "\n",
    "if RUN_LONG_STUFF_PT5:\n",
    "  # Set up the Ref frames. We find homography to closest one of these.\n",
    "  N, Height, Width, C = frames.shape\n",
    "  # Set up the canvas.\n",
    "  projectedWidth, projectedHeight, _ = panorama_bg.shape\n",
    "  Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "  \n",
    "  print(f'Tr \\n{Tr}')\n",
    "  print(f'Tr Inv \\n{np.linalg.inv(Tr)}')\n",
    "  # canvas = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "  for i in np.arange(0,N,1):\n",
    "      debug_5 = False \n",
    "      print(f'Rendering modified frames ... processing frame:{i:4}, count:{i:4}', end='\\r')\n",
    "      ref_idx, ref_arr_idx = get_closest_key_frame(i)\n",
    "      # ref_H = video_ref_homographies[ref_arr_idx, ...]\n",
    "      # H = ref_H @ video_homographies[i, ...]\n",
    "      H = video_homographies[i, ...]\n",
    "\n",
    "      # if debug_3:\n",
    "      #   plt.figure(figsize=(10,8))\n",
    "      #   plt.imshow(ref[:,:,[2,1,0]])\n",
    "      #   plt.title(f'Ref frame {i}')\n",
    "      #   plt.show()\n",
    "      #   plt.figure(figsize=(10,8))\n",
    "      #   plt.imshow(f[:,:,[2,1,0]])\n",
    "      #   plt.title(f'Frame {i}')\n",
    "      #   plt.show()\n",
    "\n",
    "      # p_ref = cv2.warpPerspective(ref, np.dot(Tr, ref_H), (projectedWidth, projectedHeight))\n",
    "      # blendOut = utils.blendImages(p1, p_ref)  # Ref is second argument.\n",
    "      # canvas = utils.blendImages(f, canvas)\n",
    "      fwd_H = np.dot(Tr, H)\n",
    "      inv_H = np.dot(np.linalg.inv(H), np.linalg.inv(Tr))\n",
    "      # print(f'H \\n{H}')\n",
    "      # print(f'H inv\\n{np.linalg.inv(H)}')\n",
    "      # print(f'fwd_H \\n{fwd_H}')\n",
    "      # print(f'inv_H \\n{inv_H}')\n",
    "      # print(f'fwd inv dot ~= 1\\n{np.dot(inv_H, fwd_H)}')\n",
    "      ret, cv2_inv_H = cv2.invert(np.dot(Tr, H))\n",
    "      assert(np.allclose(inv_H, cv2_inv_H))\n",
    "      # inverted = cv2.warpPerspective(panorama, cv2_inv_H,\n",
    "      #                                (frameWidth, frameHeight))\n",
    "      inverted_bg = cv2.warpPerspective(panorama_bg, fwd_H,\n",
    "                                     (frameWidth, frameHeight), flags=cv2.WARP_INVERSE_MAP)\n",
    "      # inverted_all = cv2.warpPerspective(panorama_all, fwd_H,\n",
    "      #                                (frameWidth, frameHeight), flags=cv2.WARP_INVERSE_MAP)\n",
    "      frames[i, ...] = orig_frames[i, ...] - inverted_bg\n",
    "      mean_bg_colors = np.mean(inverted_bg, axis=(0,1)).astype(np.uint8)\n",
    "      frames[i, ...] += mean_bg_colors\n",
    "\n",
    "      if debug_5 and (i % 50) == 0:\n",
    "        f = frames[i, ...]\n",
    "        print(f'min: {np.min(f)}, max: {np.max(f)}, '\n",
    "              f'mean: {np.mean(f)}, median: {np.median(f)}')\n",
    "        print(f)\n",
    "        plt.figure(figsize=(25,20))\n",
    "        plt.imshow(orig_frames[i][:,:,[2,1,0]])\n",
    "        plt.title(f'Frame Original {i}')\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(25,20))\n",
    "        plt.imshow(inverted_bg[:,:,[2,1,0]])\n",
    "        plt.title(f'Frame Inverted {i}')\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(25,20))\n",
    "        plt.imshow(frames[i][:,:,[2,1,0]])\n",
    "        plt.title(f'Frame Foreground {i}')\n",
    "        plt.show()\n",
    "\n",
    "  np.save('part6_frames_arr.npy', frames, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del frames\n",
    "del orig_frames\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_LONG_STUFF_PT5:\n",
    "  video_frames = np.load('part6_frames_arr.npy', allow_pickle=True)\n",
    "  # Convert BGR to RGB, ffmpeg wants RGB.\n",
    "  utils.vidwrite_from_numpy('part6_video_out.mp4', video_frames[...,[2,1,0]], framerate=30, vcodec='libx264')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8N-OaHeQJxA"
   },
   "source": [
    "## Bells and whistles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMeDlAhFQJxB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_5_starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
