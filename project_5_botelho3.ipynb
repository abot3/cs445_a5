{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XVd5QDvoQJvB"
   },
   "source": [
    "Project #5: Video Stitching and Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gd7scc-8QJvE"
   },
   "source": [
    "## CS445: Computational Photography - Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "II0kMh4yULg_"
   },
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtjcEvWArExF"
   },
   "outputs": [],
   "source": [
    "!pip uninstall opencv-python -y\n",
    "# downgrade OpenCV a bit to use SIFT\n",
    "# !pip install opencv-contrib-python==3.4.2.17 --force-reinstall\n",
    "!pip install ffmpeg-python # for converting to video\n",
    "\n",
    "import ffmpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy.linalg import svd, inv\n",
    "import utils\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGABkLumWBt_"
   },
   "outputs": [],
   "source": [
    "# modify to where you store your project data including utils\n",
    "datadir = \"/home/abot/cs445_comp_photo/cs445_a5\" \n",
    "\n",
    "utilfn = os.path.join(datadir, \"utils.py\")\n",
    "!cp \"$utilfn\" .\n",
    "imagesfn = os.path.join(datadir, \"images\")\n",
    "!cp -r \"$imagesfn\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(182736745)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QagOldZDQJvG"
   },
   "source": [
    "### Part I: Stitch two key frames \n",
    "\n",
    "#### This involves:\n",
    "1. compute homography H between two frames; \n",
    "2. project each frame onto the same surface;\n",
    "3. blend the surfaces.\n",
    "\n",
    "Check that your homography is correct by plotting four points that form a square in frame 270 and their projections in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BulGTlesQJvZ"
   },
   "outputs": [],
   "source": [
    "def score_projection(pt1, pt2):\n",
    "  '''\n",
    "  Score corresponding to the number of inliers for RANSAC\n",
    "  Input: pt1 and pt2 are 2xN arrays of N points such that pt1[:, i] and pt2[:,i] should\n",
    "          be close in Euclidean distance if they are inliers\n",
    "  Outputs: score (scalar count of inliers) and inliers (1xN logical array)\n",
    "  '''\n",
    "  kThreshold = 3.0\n",
    "  _, N = pt1.shape\n",
    "  \n",
    "  euclid_dist = np.sqrt(np.sum(np.power(pt1 - pt2, 2), axis=0))\n",
    "  # (N,) -> (1,N)\n",
    "  euclid_dist = euclid_dist[np.newaxis, :]\n",
    "  assert(euclid_dist.shape == (1,N))\n",
    "  inliers = euclid_dist < kThreshold\n",
    "  assert(inliers.shape == (1,N))\n",
    "  score = np.sum(inliers)\n",
    "  \n",
    "  return score, inliers\n",
    "\n",
    "\n",
    "def auto_homography(Ia,Ib, homography_func=None,normalization_func=None):\n",
    "    '''\n",
    "    Computes a homography that maps points from Ia to Ib\n",
    "\n",
    "    Input: Ia and Ib are images\n",
    "    Output: H is the homography\n",
    "\n",
    "    '''\n",
    "    if Ia.dtype == 'float32' and Ib.dtype == 'float32':\n",
    "        Ia = (Ia*255).astype(np.uint8)\n",
    "        Ib = (Ib*255).astype(np.uint8)\n",
    "    \n",
    "    Ia_gray = cv2.cvtColor(Ia,cv2.COLOR_BGR2GRAY)\n",
    "    Ib_gray = cv2.cvtColor(Ib,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp_a, des_a = sift.detectAndCompute(Ia_gray,None)\n",
    "    kp_b, des_b = sift.detectAndCompute(Ib_gray,None)    \n",
    "    \n",
    "    # BFMatcher with default params\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des_a,des_b, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append(m)\n",
    "   \n",
    "    numMatches = int(len(good))\n",
    "\n",
    "    matches = good\n",
    "\n",
    "    # Xa and Xb are 3xN matrices that contain homogeneous coordinates for the N\n",
    "    # matching points for each image\n",
    "    Xa = np.ones((3,numMatches))\n",
    "    Xb = np.ones((3,numMatches))\n",
    "    \n",
    "    for idx, match_i in enumerate(matches):\n",
    "        Xa[:,idx][0:2] = kp_a[match_i.queryIdx].pt\n",
    "        Xb[:,idx][0:2] = kp_b[match_i.trainIdx].pt\n",
    "\n",
    "    ## RANSAC\n",
    "    niter = 1000\n",
    "    best_score = 0\n",
    "    n_to_sample = 4 # Put the correct number of points here\n",
    "\n",
    "    for t in range(niter):\n",
    "        # estimate homography\n",
    "        subset = np.random.choice(numMatches, n_to_sample, replace=False)\n",
    "        pts1 = Xa[:,subset]\n",
    "        pts2 = Xb[:,subset]\n",
    "        \n",
    "        H_t = homography_func(pts1, pts2, normalization_func) # edit helper code below (computeHomography)\n",
    "\n",
    "        \n",
    "        # score homography\n",
    "        Xb_ = np.dot(H_t, Xa) # project points from first image to second using H\n",
    "        \n",
    "        score_t, inliers_t = score_projection(Xb[:2,:]/Xb[2,:], Xb_[:2,:]/Xb_[2,:])\n",
    "\n",
    "        if score_t > best_score:\n",
    "            best_score = score_t\n",
    "            H = H_t\n",
    "            in_idx = inliers_t\n",
    "    \n",
    "    print('best score: {:02f}'.format(best_score))\n",
    "\n",
    "    # Optionally, you may want to re-estimate H based on inliers\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgPCp98fQJvh"
   },
   "outputs": [],
   "source": [
    "def computeHomography(pts1, pts2, normalization_func=None):\n",
    "    '''\n",
    "    Compute homography that maps from pts1 to pts2 using SVD. Normalization is optional.\n",
    "     \n",
    "    Input: pts1 and pts2 are 3xN matrices for N points in homogeneous\n",
    "    coordinates. \n",
    "    \n",
    "    Output: H is a 3x3 matrix, such that pts2~=H*pts1\n",
    "    '''\n",
    "    kNumCols = 9\n",
    "    three, N = pts1.shape\n",
    "    assert(three == 3)\n",
    "    assert(N == 4)\n",
    "    orig_pts1 = pts1.copy()\n",
    "    orig_pts2 = pts2.copy()\n",
    "    \n",
    "    # Normalize the points (x) matrices\n",
    "    if normalization_func:\n",
    "      pts1, pts2, T, TP = normalization_func(pts1, pts2)\n",
    "  \n",
    "    # Aliases for indices that match lecture nomenclature. Homo coords [u, v, w]\n",
    "    u, v = [0, 1]\n",
    "    up, vp = [0, 1]\n",
    "    \n",
    "    A = np.zeros((2*N, kNumCols))\n",
    "    A[::2,0] = -pts1[u, :]  # 0th col\n",
    "    A[::2,1] = -pts1[v, :]  # 1st col\n",
    "    A[::2,2] = -1.0         # 2nd col\n",
    "    # next 3 cols are 0.\n",
    "    A[::2,6] = pts1[u , :] * pts2[up, :]  # 6th col\n",
    "    A[::2,7] = pts1[v , :] * pts2[up, :]  # 7th col\n",
    "    A[::2,8] = pts2[up, :]                # 8th col\n",
    "    \n",
    "    # 1st 3 cols are 0.\n",
    "    A[1::2,3] = -pts1[u, :]  # 3rd col\n",
    "    A[1::2,4] = -pts1[v, :]  # 4th col\n",
    "    A[1::2,5] = -1.0         # 5th col\n",
    "    A[1::2,6] = pts1[u , :] * pts2[vp, :]  # 6th col\n",
    "    A[1::2,7] = pts1[v , :] * pts2[vp, :]  # 7th col\n",
    "    A[1::2,8] = pts2[vp, :]                # 8th col\n",
    "   \n",
    "    # S is sorted in descending order. diag(S)*V = (K,K) * (K,N) so last col is multiplied by smallest singular value.\n",
    "    U, S, Vh = np.linalg.svd(A, compute_uv=True)\n",
    "    h = Vh[-1, :]\n",
    "    H = h.copy().reshape((three, three), order='C')\n",
    "    assert(h[3] == H[1,0])  # Check reshape index correct.\n",
    "    assert(h[5] == H[1,2])\n",
    "    \n",
    "    if normalization_func:\n",
    "      H = TP @ H @ T\n",
    "\n",
    "    # For scaling of H matrix by the w', or lamba homo coord see:\n",
    "    # https://math.stackexchange.com/questions/494238/how-to-compute-homography-matrix-h-from-corresponding-points-2d-2d-planar-homog\n",
    "    unscaled_homo = H @ pts1\n",
    "    scaled_homo = unscaled_homo / unscaled_homo[-1, :]\n",
    "    if not np.allclose(pts2, scaled_homo, rtol=0.01):\n",
    "      print('WARNING:')\n",
    "      print(f'pts1\\n {pts1}')\n",
    "      print(f'pts2\\n {pts2}')\n",
    "      print(f'H*pts1 \\n{unscaled_homo}\\n')\n",
    "      print(f'pts2 - H*pts1 diff {pts2 - scaled_homo}\\n')\n",
    "    assert(np.allclose(pts2, scaled_homo, rtol=0.01))\n",
    "    return H\n",
    "\n",
    "def normalizeHomography(pts1, pts2):\n",
    "  ''' Normalizes the x vectors in the equation x_p = H @ x\n",
    "  \n",
    "  Input: pts1 and pts2 are 3xN matrices for N points in homogeneous\n",
    "  coordinates. \n",
    "  \n",
    "  Output:\n",
    "    pts1_p: transformed (0 mean, unit variance) version of pts1\n",
    "    pts2_p: transformed (0 mean, unit variance) version of pts2\n",
    "    T: the transform corresponding to pts1\n",
    "    TP: the transform corresponding to pts2:\n",
    "  \n",
    "  We compute the homography on the transformed H so all points are the same scale\n",
    "  around ~1. To inver the transform and recover original, unnormalized H, we can\n",
    "  do the following:\n",
    "      H = TP @ HP @T, \n",
    " \n",
    "  pts2~=H*pts1, so pts2 is x_p, and pts1 is x.\n",
    "  \n",
    "  ~x = T @ x\n",
    "  ~x_p = Tp @ x_p\n",
    "  \n",
    "  Where ~x, and ~x_p are transformed versions of x and x_p with ~0 mean and unit\n",
    "  variance.\n",
    "  '''\n",
    "  T = np.diag([1.0,1.0,1.0])\n",
    "  TP = np.diag([1.0,1.0,1.0])\n",
    "  sigma_T = np.diag([np.std(pts1[0,:]), np.std(pts1[1,:]), 1.0])   # x,y,1\n",
    "  sigma_TP = np.diag([np.std(pts2[0,:]), np.std(pts2[1,:]), 1.0])  # x,y,1\n",
    "  mu_x, mu_y   = (np.mean(pts1[0,:]), np.mean(pts1[1,:]))  # x,y\n",
    "  mu_xp, mu_yp = (np.mean(pts2[0,:]), np.mean(pts2[1,:]))  # x,y\n",
    "  \n",
    "  T[0, -1] = -mu_x\n",
    "  T[1, -1] = -mu_y\n",
    "  TP[0, -1] = -mu_xp\n",
    "  TP[1, -1] = -mu_yp\n",
    "  \n",
    "  T = sigma_T @ T\n",
    "  TP = sigma_TP @ TP\n",
    "  \n",
    "  pts1_p = T @ pts1\n",
    "  pts2_p = TP @ pts2\n",
    "  \n",
    "  return pts1_p, pts2_p, T, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fkiAbFqvQJvo"
   },
   "outputs": [],
   "source": [
    "# images location\n",
    "im1 = './images/input/frames/f0270.jpg'\n",
    "im2 = './images/input/frames/f0450.jpg'\n",
    "\n",
    "# Load an color image in grayscale\n",
    "im1 = cv2.imread(im1)\n",
    "im2 = cv2.imread(im2)\n",
    "\n",
    "H = auto_homography(im1,im2, computeHomography, normalizeHomography)\n",
    "print(H/H.max()) \n",
    "\n",
    "# plot the frames here\n",
    "box_pts = np.array([[300, 400, 400, 300, 300], [100, 100, 200, 200, 100], [1, 1, 1, 1, 1]])\n",
    "plt.figure()\n",
    "plt.imshow(im1[:,:,[2,1,0]])\n",
    "plt.plot(box_pts[0,:], box_pts[1, :], 'r-')\n",
    "\n",
    "# TO DO: project points into im2 and display the projected lines on im2\n",
    "unscaled_homo = H @ box_pts\n",
    "scaled_homo = unscaled_homo / unscaled_homo[-1, :]\n",
    "plt.figure()\n",
    "plt.imshow(im2[:,:,[2,1,0]])\n",
    "plt.plot(scaled_homo[0,:], scaled_homo[1, :], 'r-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDd6PwrGQJvw"
   },
   "outputs": [],
   "source": [
    "projectedWidth = 1600\n",
    "projectedHeight = 500\n",
    "Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "canvas = np.zeros((projectedHeight, projectedWidth))\n",
    "\n",
    "# Projects im1 and im2 according to T1 and T2 to an image of size WxH and then\n",
    "# blends the projected images by filling any zero values in projIm2 with values\n",
    "# from projIm1\n",
    "projIm1 = cv2.warpPerspective(im1, np.dot(Tr,H), (projectedWidth, projectedHeight))\n",
    "projIm2 = cv2.warpPerspective(im2, Tr, (projectedWidth, projectedHeight))\n",
    "blendOut = utils.blendImages(projIm1, projIm2) \n",
    "\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.imshow(blendOut[:,:,[2,1,0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1PigMkPQJv4"
   },
   "source": [
    "### Part II: Panorama using five key frames\n",
    "\n",
    "Produce a panorama by mapping five key frames [90, 270, 450, 630, 810] onto the same reference frame 450.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SgCFur1QJwC"
   },
   "outputs": [],
   "source": [
    "key_frames_idx = np.array([90, 270, 450, 630, 810])-1\n",
    "\n",
    "frames = np.zeros((len(key_frames_idx), im1.shape[0], im1.shape[1], im1.shape[2]),dtype='uint8')\n",
    "for n in range(len(key_frames_idx)):\n",
    "  frames[n] = cv2.imread(\"./images/input/frames/f0{num}.jpg\".format(num=str(key_frames_idx[n]+1).zfill(3)))\n",
    "\n",
    "def warp_frames(frames: List[np.ndarray]) -> np.ndarray:\n",
    "  projectedWidth = 1600\n",
    "  projectedHeight = 500\n",
    "  Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]]).astype(np.float32)\n",
    "  canvas = np.zeros((projectedHeight, projectedWidth, 3))\n",
    "  \n",
    "  # We reference everything to the 450th frame. Add 1 so we keep the black\n",
    "  # pixels when using blendImages.\n",
    "  kRefFrame = frames[len(frames)//2].copy()\n",
    "  kRefFrame[kRefFrame == 0] = 1\n",
    "\n",
    "  for f in frames:\n",
    "    H = auto_homography(f, kRefFrame, computeHomography)\n",
    "    p1 = cv2.warpPerspective(f, np.dot(Tr,H), (projectedWidth, projectedHeight))\n",
    "    p_ref = cv2.warpPerspective(kRefFrame, Tr, (projectedWidth, projectedHeight))\n",
    "    blendOut = utils.blendImages(p1, p_ref)  # Ref is second argument.\n",
    "    print(f'p1 shape {p1.shape}, p_ref shape {p_ref.shape}')\n",
    "    print(f'blendOut {blendOut.shape}, canvas {canvas.shape}')\n",
    "    canvas = utils.blendImages(blendOut, canvas)\n",
    "    plt.figure(figsize=(25,20))\n",
    "    plt.imshow(blendOut[:,:,[2,1,0]])\n",
    "    \n",
    "  return canvas\n",
    "\n",
    "canvas = warp_frames(frames)\n",
    "plt.figure(figsize=(25,20))\n",
    "plt.imshow(canvas[:,:,[2,1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APdyMw_NQJwK"
   },
   "source": [
    "### Part 3: Map the video to the reference plane\n",
    "\n",
    "Project each frame onto the reference frame (using same size panorama) to create a video that shows the portion of the panorama revealed by each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAXyIkYyQJwT"
   },
   "outputs": [],
   "source": [
    "# read all the images\n",
    "import os \n",
    "dir_frames = 'images/input/frames'\n",
    "filenames = []\n",
    "filesinfo = os.scandir(dir_frames)\n",
    "\n",
    "filenames = [f.path for f in filesinfo if f.name.endswith(\".jpg\")]\n",
    "filenames.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "frameCount = len(filenames)\n",
    "frameHeight, frameWidth, frameChannels = cv2.imread(filenames[0]).shape\n",
    "frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype='uint8')\n",
    "\n",
    "for idx, file_i in enumerate(filenames):\n",
    "  frames[idx] = cv2.imread(file_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0b8N2rP9PDVL"
   },
   "outputs": [],
   "source": [
    "# TO DO part 3 solution\n",
    "\n",
    "# create your video (see tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dg2O-zH_QJw0"
   },
   "source": [
    "### Part 4: Create background panorama\n",
    "\n",
    "Create a background panorama based on the result from Part 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ammv-rsQJw1"
   },
   "outputs": [],
   "source": [
    "# TO DO part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IqzWZwrQJw4"
   },
   "source": [
    "### Part 5: Create background movie\n",
    "\n",
    "Generate a movie that looks like the input movie but shows only background pixels. For each frame of the movie, you need to estimate a projection from the panorama to that frame. Your solution can use the background image you created in Part 4 and the per-frame homographies you created in Part 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dzy12p1bQJw4"
   },
   "outputs": [],
   "source": [
    "# TO DO part 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0y7i7hBQJw7"
   },
   "source": [
    "### Part 6: Create foreground movie\n",
    "\n",
    "In the background video, moving objects are removed. In each frame, those pixels that are different enough than the background color are considered foreground. For each frame determine foreground pixels and generate a movie that emphasizes or includes only foreground pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mcg6jC_9QJw8"
   },
   "outputs": [],
   "source": [
    "# TO DO part 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8N-OaHeQJxA"
   },
   "source": [
    "## Bells and whistles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMeDlAhFQJxB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_5_starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
